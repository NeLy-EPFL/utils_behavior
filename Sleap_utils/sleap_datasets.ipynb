{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sleap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import scipy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = sleap.Labels.load_file(\"/Users/ulric/Documents/Documents/MaximeModel/LabeledFrames.train.pkg.slp\")\n",
    "labels = sleap.Labels.load_file(\"/mnt/labserver/DURRIEU_Matthias/Code/Sleap_Pretrained_Maxime/LabeledFrames.train.pkg.slp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first frame\n",
    "\n",
    "frame0 = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get instances\n",
    "\n",
    "instances = frame0.instances\n",
    "\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = instances[0].points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = instances[0].numpy()\n",
    "\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new value to the array\n",
    "\n",
    "array = np.append(array, [0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances[0].pts = sleap.Instance.from_numpy(array, skeleton=labels.skeletons[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances[5].points[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame1 = labels[1]\n",
    "instances1 = frame1.instances\n",
    "instances1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort instances by y position\n",
    "instances1.sort(key=lambda x: x[0].y)\n",
    "instances1\n",
    "#instances.sort(key=lambda x: x.centroid[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[1].instances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes : 1) It's fairly easy to sort flies instances by their y positions 2) because the subvariables (ex: instances) are symlinked to the original label variable, the orginial can be edited by editing the subvariable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in range(len(labels)):\n",
    "    labels[f].instances.sort(key=lambda x: x[0].y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[10].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_0 = labels[0]\n",
    "\n",
    "frame_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = frame_0.image\n",
    "\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape img to a 832x832 image\n",
    "img_shaped = img[0:832, 0:832]\n",
    "\n",
    "plt.imshow(img_shaped, cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with cropped video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath = '/Users/ulric/Movies/TrainingVids/Crops/Arena1/Arena1.mp4'\n",
    "# Display the frame 6254 of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath)\n",
    "cap.set(1, 6254)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking good, do the same with arena 4 which is slightly more distinguishable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath4 = '/Users/ulric/Movies/TrainingVids/Crops/Arena4/Arena4.mp4'\n",
    "# Display the frame 6254 of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath4)\n",
    "cap.set(1, 6254)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I tested shifting by 6 frames, let's see if this is consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(CropPath4)\n",
    "cap.set(1, 6254-6)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be! Then shift everything by 6 frames should be simpler than working on subsets of the videos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Let's check the arena 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath5 = '/Users/ulric/Movies/TrainingVids/Crops/Arena5/Arena5.mp4'\n",
    "# Display the frame 6254 of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath5)\n",
    "cap.set(1, 6254)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might be some inconsistency during the writing process. Then better strategy is to use the cropping parameters and generate the cropped frames from the original labeled frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_1 = labels[1]\n",
    "\n",
    "frame_1\n",
    "\n",
    "img = frame_1.image\n",
    "\n",
    "img_shaped = img[0:832, 0:832]\n",
    "\n",
    "plt.imshow(img_shaped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath = '/Users/ulric/Movies/TrainingVids/Crops/Arena1/Arena1.mp4'\n",
    "# Display the frame corresponding to the frame_1 idx of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath)\n",
    "cap.set(1, frame_1.frame_idx-6)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 6 frames discrepancy between the original and the cropped frames. This is due to the fact that the cropping is done on the original frames, while the labeled frames are generated from the cropped frames. This is not a problem, as long as there is the same discrepancy everywhere."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check with some other frame closer to the beginning of the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List frames indices from the labels\n",
    "frame_idx = []\n",
    "for i in range(len(labels)):\n",
    "    frame_idx.append(labels[i].frame_idx)\n",
    "    \n",
    "frame_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(frame_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_14 = labels[14]\n",
    "\n",
    "frame_14\n",
    "\n",
    "img = frame_14.image\n",
    "\n",
    "img_shaped = img[0:832, 0:832]\n",
    "\n",
    "plt.imshow(img_shaped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath = '/Users/ulric/Movies/TrainingVids/Crops/Arena1/Arena1.mp4'\n",
    "# Display the frame corresponding to the frame_1 idx of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath)\n",
    "cap.set(1, frame_14.frame_idx-6)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath3 = '/Users/ulric/Movies/TrainingVids/Crops/Arena3/Arena3.mp4'\n",
    "# Display the frame corresponding to the frame_1 idx of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath3)\n",
    "cap.set(1, frame_14.frame_idx-6)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ffmpeg can screw up when trimming if I forget a flag to synchronise frames. Most of the time this will happen on the first frames. OpenCV should not have this problem, which explains why the video writing was fine."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add labels to cropped frames"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First work with one frame on one video to make sure the syntax is right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_path = '/Users/ulric/Movies/TrainingVids/Arena_indices.npy'\n",
    "param_path = '/mnt/labserver/DURRIEU_Matthias/Code/Sleap_Pretrained_Maxime/TrainingVideo/Arena_indices.npy'\n",
    "# Load the parameters\n",
    "Arena_indices = np.load(param_path, allow_pickle=True)\n",
    "\n",
    "# Convert it to a list\n",
    "Arena_indices = Arena_indices.tolist()\n",
    "\n",
    "Arena_indices\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a test frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropPath = '/Users/ulric/Movies/TrainingVids/Crops/Arena1/Arena1.mp4'\n",
    "# Display the frame corresponding to the frame_1 idx of the video CropPath\n",
    "cap = cv2.VideoCapture(CropPath)\n",
    "cap.set(1, frame_1.frame_idx-6)\n",
    "ret, frame = cap.read()\n",
    "plt.imshow(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels from the original frame\n",
    "frame_1 = labels[1]\n",
    "\n",
    "labs = frame_1.instances[0].points\n",
    "\n",
    "labs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CorrLabs = labs\n",
    "\n",
    "for i in range(len(labs)):\n",
    "    CorrLabs[i].y = labs[i].y - Arena_indices[0][0]\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = frame_1.instances[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabFrame = sleap.LabeledFrame(video = sleap.load_video(CropPath), frame_idx = frame_1.frame_idx-6, instances = [sleap.Instance.from_numpy(pts, skeleton=labels.skeletons[0])])\n",
    "\n",
    "\n",
    "LabFrame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First converting the instances points as numpy array worked well to be able to associate frame with instances. Now I need to convert them using sleap methods and skeleton definition to have the edges too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabFrame.instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap.nn.viz.plot_instance(LabFrame.instances[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LabFrame.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[1].instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[1].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important note: the labels are not sorted by value but by the order they were added to the frame. Frames need to be sorted by y value before processing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat the same procedure with all the crops of the same frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the original labels for a fresh start\n",
    "\n",
    "labels = sleap.Labels.load_file(\"/mnt/labserver/DURRIEU_Matthias/Code/Sleap_Pretrained_Maxime/LabeledFrames.train.pkg.slp\")\n",
    "#labels = sleap.Labels.load_file(\"/Users/ulric/Documents/Documents/MaximeModel/LabeledFrames.train.pkg.slp\")\n",
    "\n",
    "for f in range(len(labels)):\n",
    "    labels[f].instances.sort(key=lambda x: x[0].y)\n",
    "\n",
    "# First define which frame it is : same as the original frame - 6\n",
    "\n",
    "\n",
    "frame_idx = labels[1].frame_idx - 6\n",
    "\n",
    "# Create the dataset\n",
    "\n",
    "CropLabsData = []\n",
    "\n",
    "#LabFrame = sleap.io.dataset.LabeledFrameDataset(labels, video_paths = [CropPath], frame_indices = [frame_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_path = '/Users/ulric/Movies/TrainingVids/Arena_indices.npy'\n",
    "param_path = '/mnt/labserver/DURRIEU_Matthias/Code/Sleap_Pretrained_Maxime/TrainingVideo/Arena_indices.npy'\n",
    "# Load the parameters\n",
    "Arena_indices = np.load(param_path, allow_pickle=True)\n",
    "\n",
    "# Convert it to a list\n",
    "Arena_indices = Arena_indices.tolist()\n",
    "\n",
    "Arena_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all first values of elements in Arena_indices\n",
    "Crops_adjust = [x[0] for x in Arena_indices]\n",
    "Crops_adjust\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to all the videos in the /Users/ulric/Movies/TrainingVids/Crops folder\n",
    "PathToCrops = Path(\"/mnt/labserver/DURRIEU_Matthias/Code/Sleap_Pretrained_Maxime/TrainingVideo/Crops/\")\n",
    "VidPaths = PathToCrops.rglob(\"*.mp4\")\n",
    "# Put the path to the videos in a list\n",
    "CropVids = [vid.as_posix() for vid in VidPaths]\n",
    "# Sort the list\n",
    "CropVids.sort()\n",
    "CropVids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I tried embedding this in a dataset, but video referencing was bad. Instead I'll first create the dataset then fill it with labeled frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = [sleap.load_video(v) for v in CropVids]\n",
    "vids\n",
    "\n",
    "Training_data_Cropped = sleap.io.dataset.Labels(\n",
    "    labeled_frames = [],\n",
    "    videos = vids,\n",
    "    skeletons = labels.skeletons,\n",
    ")\n",
    "\n",
    "Training_data_Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped.videos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This chunk of code is to adjust the labels to the cropped videos : For each labeled frame, for each instance in this labeled frame, for each point in these instances, adjust the y coordinate by the corresponding value in Crops_adjust\n",
    "for f in range(len(labels)):\n",
    "    frame = labels[f]\n",
    "    for i in range(len(frame.instances)):\n",
    "        inst = frame.instances[i]\n",
    "        for j in range(len(inst.points)):\n",
    "            inst.points[j].y = inst.points[j].y - Crops_adjust[i]\n",
    "        pts = inst.numpy()\n",
    "        Training_data_Cropped.labeled_frames.append(sleap.LabeledFrame(\n",
    "        video = Training_data_Cropped.videos[i], \n",
    "        frame_idx = labels[f].frame_idx-6, \n",
    "        instances = [sleap.Instance.from_numpy(pts, skeleton=labels.skeletons[0])]))\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped[0].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird, the labels seem to be shifted as if they were already good but by adjusting them I messed them up.\n",
    "\n",
    "*warning* : Always reload original dataset otherwise adjustments will be kept from previous runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropLabsData[258].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus : make it a proper dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right now it is a list of individual labeled frames, there must be a better way to implement this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped = sleap.io.dataset.Labels(\n",
    "    #labeled_frames = CropLabsData,\n",
    "    videos = vids,\n",
    "    skeletons = labels.skeletons,\n",
    ")\n",
    "\n",
    "Training_data_Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CropLabsData"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I just need to embed this in a Dataset class and it should be good to go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vids = [sleap.load_video(v) for v in CropVids]\n",
    "vids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped = sleap.io.dataset.Labels(\n",
    "    labeled_frames = CropLabsData,\n",
    "    #videos = vids,\n",
    "    skeletons = labels.skeletons,\n",
    ")\n",
    "\n",
    "Training_data_Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped.videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_data_Cropped.videos = vids\n",
    "\n",
    "Training_data_Cropped.videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataset\n",
    "\n",
    "Training_data_Cropped.save(\"/mnt/labserver/DURRIEU_Matthias/Code/Training_data_Cropped.train.pkg.slp\")\n",
    "\n",
    "#sleap.save(Training_data_Cropped, \"/Volumes/Ramdya-Lab/DURRIEU_Matthias/Code/Training_data_Cropped.train.pkg.slp\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to get the different instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LabsFly1 = frame_0.instances[0]\n",
    "\n",
    "LabsFly1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to edit labels in an instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the instance\n",
    "# Add 200 to the y coordinate of each point\n",
    "for p in range(len(LabsFly1.points)):\n",
    "    LabsFly1.points[p].y = LabsFly1.points[p].y + 200\n",
    "    \n",
    "LabsFly1\n",
    "\n",
    "\n",
    "#ModInst = i + 200 for i in frame_0.instances[0].points"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to edit all instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insts = frame_0.instances\n",
    "Insts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(Insts)):\n",
    "    Fly = Insts[i]\n",
    "    for p in range(len(Fly.points)):\n",
    "        Fly.points[p].y = Fly.points[p].y + 200\n",
    "        \n",
    "Insts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop the frames according to arenas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im_full_gray = cv2.cvtColor(img_shaped, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(img_shaped, cmap=\"gray\", vmin=0, vmax=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = img_shaped.sum(axis=1)\n",
    "\n",
    "# convert rows to a list\n",
    "[rows]\n",
    "\n",
    "#plt.plot(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks = scipy.signal.find_peaks(rows,\n",
    "                                distance=40,\n",
    "                                height=30_000,)\n",
    "\n",
    "# Check that peaks are correctly located\n",
    "\n",
    "x = np.array(range(0,len(rows[0])))\n",
    "PeaksPos = (x[peaks[0]], rows[0][peaks[0]])\n",
    "\n",
    "plt.plot(rows)\n",
    "plt.scatter(PeaksPos[0], PeaksPos[1])\n",
    "plt.show()\n",
    "#hv.Histogram(rows).opts(tools=['hover'])*hv.Points(PeaksPos).opts(color='orange', tools=['hover'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows[:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually this should be done externally using my already built library. I'll just import cropping parameters to use as transformation values for the new labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "NewLabs = sleap.Labels(skeletons=labels.skeletons)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path to all the videos in the /Users/ulric/Movies/TrainingVids/Crops folder\n",
    "PathToCrops = Path(\"/Users/ulric/Movies/TrainingVids/Crops\")\n",
    "VidPaths = PathToCrops.rglob(\"*.mp4\")\n",
    "# Put the path to the videos in a list\n",
    "CropVids = [vid for vid in VidPaths]\n",
    "CropVids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in CropVids:\n",
    "    NewLabs.add_video(v)\n",
    "\n",
    "NewLabs.videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.labeled_frames[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each frame split instances into separate labels\n",
    "for f in range(len(labels)):\n",
    "    frame = labels[f]\n",
    "    for i in range(len(frame.instances)):\n",
    "        Fly = frame.instances[i]\n",
    "        NewLabs.add_instance(Fly, frame_idx=f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotation of labes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame0 = labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotate the points coordinates by 90 degrees\n",
    "for i in range(len(frame0.instances)):\n",
    "    Fly = frame0.instances[i]\n",
    "    for p in range(len(Fly.points)):\n",
    "        Fly.points[p].x, Fly.points[p].y = Fly.points[p].y, Fly.points[p].x\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "203ad26756b28f850b0d6db7d291cbdc36fbe56f3d44dd9920742f6b638c3b4b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
